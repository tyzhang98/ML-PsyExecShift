{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据集A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值填充前:\n",
      "stroop_incongruent_rt            0\n",
      "stroop_interference_effect_rt    4\n",
      "nogo_acc                         0\n",
      "switch_cost                      1\n",
      "rm_1750_acc                      8\n",
      "rm_750_acc                       1\n",
      "dsbt_span                        0\n",
      "dtype: int64\n",
      "[IterativeImputer] Completing matrix with shape (364, 7)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.00\n",
      "[IterativeImputer] Change: 337.1600486648706, scaled tolerance: 1.36346256410256 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 0.01\n",
      "[IterativeImputer] Change: 1.0661398149929937, scaled tolerance: 1.36346256410256 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "缺失值填充后:\n",
      "stroop_incongruent_rt            0\n",
      "stroop_interference_effect_rt    0\n",
      "nogo_acc                         0\n",
      "switch_cost                      0\n",
      "rm_1750_acc                      0\n",
      "rm_750_acc                       0\n",
      "dsbt_span                        0\n",
      "dtype: int64\n",
      "数据处理完成，已保存至 预处理后的数据集A.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel('rawdata/数据集A.xlsx')\n",
    "\n",
    "# 仅指定要处理的行为变量\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', \n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "# 提取要处理的数据\n",
    "behavior_data = df[behavior_variables]\n",
    "\n",
    "# 处理前缺失值统计\n",
    "missing_values_before = behavior_data.isna().sum()\n",
    "print(\"缺失值填充前:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# 使用 IterativeImputer 进行多重插补（MICE）\n",
    "imputer = IterativeImputer(\n",
    "    random_state=42, \n",
    "    max_iter=10,  # 增加最大迭代次数\n",
    "    tol=1e-3,     # 调整收敛容忍度\n",
    "    verbose=2     # 显示填充进度\n",
    ")\n",
    "imputed_behavior_data = imputer.fit_transform(behavior_data)\n",
    "\n",
    "# 将填充后的数据转换回 DataFrame\n",
    "behavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\n",
    "\n",
    "# 仅更新处理过的字段，保持其他字段不变\n",
    "df.update(behavior_df)\n",
    "\n",
    "# 处理后缺失值统计\n",
    "missing_values_after = df[behavior_variables].isna().sum()\n",
    "print(\"缺失值填充后:\")\n",
    "print(missing_values_after)\n",
    "\n",
    "# 保存处理后的数据\n",
    "output_path = '预处理后的数据集A.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"数据处理完成，已保存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据集B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值填充前:\n",
      "stroop_incongruent_rt            1\n",
      "stroop_interference_effect_rt    0\n",
      "nogo_acc                         0\n",
      "switch_cost                      0\n",
      "rm_1750_acc                      1\n",
      "rm_750_acc                       0\n",
      "dsbt_span                        0\n",
      "dtype: int64\n",
      "[IterativeImputer] Completing matrix with shape (94, 7)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.01\n",
      "[IterativeImputer] Change: 40.941604742338086, scaled tolerance: 1.1744642857142857 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 0.02\n",
      "[IterativeImputer] Change: 0.0002507349138340942, scaled tolerance: 1.1744642857142857 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "缺失值填充后:\n",
      "stroop_incongruent_rt            0\n",
      "stroop_interference_effect_rt    0\n",
      "nogo_acc                         0\n",
      "switch_cost                      0\n",
      "rm_1750_acc                      0\n",
      "rm_750_acc                       0\n",
      "dsbt_span                        0\n",
      "dtype: int64\n",
      "数据处理完成，已保存至 预处理后的数据集B前测.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel('rawdata/数据集B前测.xlsx')\n",
    "\n",
    "# 仅指定要处理的行为变量\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', \n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "\n",
    "# 提取要处理的数据\n",
    "behavior_data = df[behavior_variables]\n",
    "\n",
    "# 处理前缺失值统计\n",
    "missing_values_before = behavior_data.isna().sum()\n",
    "print(\"缺失值填充前:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# 使用 IterativeImputer 进行多重插补（MICE）\n",
    "imputer = IterativeImputer(\n",
    "    random_state=42, \n",
    "    max_iter=10,  # 增加最大迭代次数\n",
    "    tol=1e-3,     # 调整收敛容忍度\n",
    "    verbose=2     # 显示填充进度\n",
    ")\n",
    "imputed_behavior_data = imputer.fit_transform(behavior_data)\n",
    "\n",
    "# 将填充后的数据转换回 DataFrame\n",
    "behavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\n",
    "\n",
    "# 仅更新处理过的字段，保持其他字段不变\n",
    "df.update(behavior_df)\n",
    "\n",
    "# 处理后缺失值统计\n",
    "missing_values_after = df[behavior_variables].isna().sum()\n",
    "print(\"缺失值填充后:\")\n",
    "print(missing_values_after)\n",
    "\n",
    "# 保存处理后的数据\n",
    "output_path = '预处理后的数据集B前测.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"数据处理完成，已保存至 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值填充前:\n",
      "stroop_incongruent_rt            0\n",
      "stroop_interference_effect_rt    0\n",
      "nogo_acc                         0\n",
      "switch_cost                      0\n",
      "rm_1750_acc                      2\n",
      "rm_750_acc                       1\n",
      "dsbt_span                        3\n",
      "dtype: int64\n",
      "[IterativeImputer] Completing matrix with shape (94, 7)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.00\n",
      "[IterativeImputer] Change: 0.787441138087691, scaled tolerance: 1.19425 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "缺失值填充后:\n",
      "stroop_incongruent_rt            0\n",
      "stroop_interference_effect_rt    0\n",
      "nogo_acc                         0\n",
      "switch_cost                      0\n",
      "rm_1750_acc                      0\n",
      "rm_750_acc                       0\n",
      "dsbt_span                        0\n",
      "dtype: int64\n",
      "数据处理完成，已保存至 预处理后的数据集B后测.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel('rawdata/数据集B后测.xlsx')\n",
    "\n",
    "# 仅指定要处理的行为变量\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', \n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "\n",
    "# 提取要处理的数据\n",
    "behavior_data = df[behavior_variables]\n",
    "\n",
    "# 处理前缺失值统计\n",
    "missing_values_before = behavior_data.isna().sum()\n",
    "print(\"缺失值填充前:\")\n",
    "print(missing_values_before)\n",
    "\n",
    "# 使用 IterativeImputer 进行多重插补（MICE）\n",
    "imputer = IterativeImputer(\n",
    "    random_state=42, \n",
    "    max_iter=10,  # 增加最大迭代次数\n",
    "    tol=1e-3,     # 调整收敛容忍度\n",
    "    verbose=2     # 显示填充进度\n",
    ")\n",
    "imputed_behavior_data = imputer.fit_transform(behavior_data)\n",
    "\n",
    "# 将填充后的数据转换回 DataFrame\n",
    "behavior_df = pd.DataFrame(imputed_behavior_data, columns=behavior_variables)\n",
    "\n",
    "# 仅更新处理过的字段，保持其他字段不变\n",
    "df.update(behavior_df)\n",
    "\n",
    "# 处理后缺失值统计\n",
    "missing_values_after = df[behavior_variables].isna().sum()\n",
    "print(\"缺失值填充后:\")\n",
    "print(missing_values_after)\n",
    "\n",
    "# 保存处理后的数据\n",
    "output_path = '预处理后的数据集B后测.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"数据处理完成，已保存至 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于HC矫正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel 文件的列名: ['id', 'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', 'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span', 'group', 'age', 'gender', 'education_years', 'dose equivalent to olanzapine']\n",
      "   stroop_incongruent_rt  stroop_interference_effect_rt  nogo_acc  \\\n",
      "0            -738.242132                     735.613724 -0.655208   \n",
      "1            -731.331369                     727.396617 -1.866666   \n",
      "2            -737.677914                     732.902322 -1.586574   \n",
      "3            -746.307821                     740.546734 -1.031932   \n",
      "4            -735.930451                     729.185446 -2.799495   \n",
      "\n",
      "   switch_cost  rm_1750_acc  rm_750_acc  dsbt_span  \n",
      "0  -303.808399    -1.585067   -2.048285  -6.476738  \n",
      "1  -285.191406     0.539985    0.791846  -5.722215  \n",
      "2  -303.063392    -2.752286   -3.008174  -6.974526  \n",
      "3  -285.788167    -1.405756   -3.196904  -6.491598  \n",
      "4  -290.812975    -1.595482   -2.827024  -6.887146  \n",
      "   stroop_incongruent_rt  stroop_interference_effect_rt  nogo_acc  \\\n",
      "0            -668.468770                     472.737383 -0.341290   \n",
      "1            -658.860649                     462.189560 -1.831999   \n",
      "2            -690.228184                     492.043867 -1.054630   \n",
      "3            -687.131249                     488.666539 -0.065394   \n",
      "4            -682.397528                     483.146635 -0.713083   \n",
      "\n",
      "   switch_cost  rm_1750_acc  rm_750_acc  dsbt_span  \n",
      "0  -185.483299     0.072327   -0.084050  -5.424842  \n",
      "1  -172.597758     0.257514   -0.105744  -5.891134  \n",
      "2  -239.178533     0.531875    0.323126  -5.517346  \n",
      "3  -198.719864     0.274264    0.912996  -4.823242  \n",
      "4  -227.702450    -0.480533    0.545471  -6.762047  \n",
      "校正并标准化完成，数据已保存到 './table/校正并标准化后的患者行为变量数据-数据集A.xlsx' 和 './table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx'.\n",
      "                              Corrected and Standardized Patient  \\\n",
      "stroop_incongruent_rt                            -714.32 ± 23.75   \n",
      "stroop_interference_effect_rt                     615.48 ± 74.59   \n",
      "nogo_acc                                            -1.33 ± 1.16   \n",
      "switch_cost                                      -265.96 ± 32.88   \n",
      "rm_1750_acc                                         -1.37 ± 1.17   \n",
      "rm_750_acc                                           -1.3 ± 1.33   \n",
      "dsbt_span                                            -6.34 ± 1.0   \n",
      "\n",
      "                              Corrected and Standardized Control  \n",
      "stroop_incongruent_rt                            -663.61 ± 32.74  \n",
      "stroop_interference_effect_rt                     384.97 ± 74.52  \n",
      "nogo_acc                                             -0.88 ± 1.0  \n",
      "switch_cost                                      -198.95 ± 39.48  \n",
      "rm_1750_acc                                          -0.74 ± 1.0  \n",
      "rm_750_acc                                          -0.66 ± 0.99  \n",
      "dsbt_span                                           -6.06 ± 1.03  \n",
      "校正并标准化后的均值和标准差已保存到 './table/校正并标准化后的行为变量均值和标准差-数据集A.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('预处理后的数据集A.xlsx')\n",
    "\n",
    "# 统一列名格式（小写，去空格，替换符号）\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace('-', '_').str.replace(',', '')\n",
    "\n",
    "# 打印实际的列名，确保匹配\n",
    "print(\"Excel 文件的列名:\", df.columns.tolist())\n",
    "\n",
    "# 重新定义 behavior_variables，确保与实际列名匹配\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc',\n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "# 确保 behavior_variables 在数据集中存在\n",
    "missing_columns = [col for col in behavior_variables if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"以下列在数据集中未找到，请检查拼写或格式: {missing_columns}\")\n",
    "\n",
    "# 统一 Group 字段大小写\n",
    "df['group'] = pd.to_numeric(df['group'], errors='coerce')  # 转换为数值型\n",
    "df.dropna(subset=['group'], inplace=True)  # 删除无效数据\n",
    "\n",
    "# 根据 Group 字段筛选数据\n",
    "patients_df = df[df['group'] == 1].copy()  # SCZ 组\n",
    "control_df = df[df['group'] == 2].copy()  # HC 组\n",
    "\n",
    "# 确保数据集不为空\n",
    "if patients_df.empty or control_df.empty:\n",
    "    raise ValueError(\"筛选出的患者组或对照组为空，请检查 Group 字段的值是否正确！\")\n",
    "\n",
    "# 定义其他变量\n",
    "continuous_variables = ['age', 'education_years']\n",
    "categorical_variables = ['gender']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "def one_hot_encode(df, categorical_vars):\n",
    "    for var in categorical_vars:\n",
    "        if var in df.columns:\n",
    "            dummies = pd.get_dummies(df[var], prefix=var, drop_first=True)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "patients_df = one_hot_encode(patients_df, categorical_variables)\n",
    "control_df = one_hot_encode(control_df, categorical_variables)\n",
    "\n",
    "# 标准化连续变量\n",
    "scaler = StandardScaler()\n",
    "control_df[continuous_variables] = scaler.fit_transform(control_df[continuous_variables])\n",
    "patients_df[continuous_variables] = scaler.transform(patients_df[continuous_variables])\n",
    "\n",
    "# 从对照组DataFrame中提取行为变量数据\n",
    "control_data = control_df[behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(control_data)\n",
    "\n",
    "# 使用对照组的标准化参数标准化患者组数据\n",
    "standardized_patient_data = scaler.transform(patients_df[behavior_variables])\n",
    "standardized_patient_df = pd.DataFrame(standardized_patient_data, columns=behavior_variables)\n",
    "\n",
    "# 处理 Healthy Controls 组\n",
    "standardized_control_data = scaler.transform(control_df[behavior_variables])\n",
    "standardized_control_df = pd.DataFrame(standardized_control_data, columns=behavior_variables)\n",
    "\n",
    "# 从数据框中获取所有人口学变量（已独热编码和标准化）\n",
    "demographic_variables = [col for col in control_df.columns if col not in behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合回归模型校正人口学效应\n",
    "corrected_patient_data = pd.DataFrame()\n",
    "corrected_control_data = pd.DataFrame()\n",
    "\n",
    "for variable in behavior_variables:\n",
    "    model = LinearRegression()\n",
    "    model.fit(control_df[demographic_variables], control_df[variable])\n",
    "    correction_patients = model.predict(patients_df[demographic_variables])\n",
    "    correction_controls = model.predict(control_df[demographic_variables])\n",
    "    corrected_patient_data[variable] = standardized_patient_df[variable] - correction_patients\n",
    "    corrected_control_data[variable] = standardized_control_df[variable] - correction_controls\n",
    "\n",
    "# 保存患者组和健康对照组的校正并标准化后的数据\n",
    "corrected_patient_df = pd.DataFrame(corrected_patient_data)\n",
    "corrected_control_df = pd.DataFrame(corrected_control_data)\n",
    "\n",
    "corrected_patient_df.to_excel('./table/校正并标准化后的患者行为变量数据-数据集A.xlsx', index=False)\n",
    "corrected_control_df.to_excel('./table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx', index=False)\n",
    "\n",
    "# 打印校正并标准化后的DataFrame\n",
    "print(corrected_patient_df.head())\n",
    "print(corrected_control_df.head())\n",
    "\n",
    "print(\"校正并标准化完成，数据已保存到 './table/校正并标准化后的患者行为变量数据-数据集A.xlsx' 和 './table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx'.\")\n",
    "\n",
    "# 计算校正并标准化后的均值和标准差\n",
    "corrected_patient_means = corrected_patient_df.mean().round(2)\n",
    "corrected_patient_stds = corrected_patient_df.std().round(2)\n",
    "corrected_control_means = corrected_control_df.mean().round(2)\n",
    "corrected_control_stds = corrected_control_df.std().round(2)\n",
    "\n",
    "# 创建一个DataFrame来存储结果，以“均值±标准差”格式显示\n",
    "summary_df = pd.DataFrame({\n",
    "    'Corrected and Standardized Patient': corrected_patient_means.astype(str) + ' ± ' + corrected_patient_stds.astype(str),\n",
    "    'Corrected and Standardized Control': corrected_control_means.astype(str) + ' ± ' + corrected_control_stds.astype(str)\n",
    "}, index=behavior_variables)\n",
    "\n",
    "# 打印结果\n",
    "print(summary_df)\n",
    "\n",
    "# 保存结果为Excel文件\n",
    "summary_df.to_excel('./table/校正并标准化后的行为变量均值和标准差-数据集A.xlsx')\n",
    "\n",
    "print(\"校正并标准化后的均值和标准差已保存到 './table/校正并标准化后的行为变量均值和标准差-数据集A.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 校正数据集B前测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCZ 数据集的列名: ['id', 'group', 'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', 'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span', 'age', 'education_years', 'gender']\n",
      "HC 数据集的列名: ['id', 'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', 'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span', 'group', 'panss_n', 'panss_p', 'panss_gp', 'dose equivalent to olanzapine', 'age', 'gender', 'education_years', 'panss_t']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['panss_n', 'panss_p', 'panss_gp', 'dose equivalent to olanzapine', 'panss_t'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m     93\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(control_df[demographic_variables], control_df[variable])\n\u001b[0;32m---> 94\u001b[0m correction_patients \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mpatients_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdemographic_variables\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     95\u001b[0m correction_controls \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(control_df[demographic_variables])\n\u001b[1;32m     96\u001b[0m corrected_patient_data[variable] \u001b[38;5;241m=\u001b[39m standardized_patient_df[variable] \u001b[38;5;241m-\u001b[39m correction_patients\n",
      "File \u001b[0;32m~/Vs_code/venv2_ml/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Vs_code/venv2_ml/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Vs_code/venv2_ml/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['panss_n', 'panss_p', 'panss_gp', 'dose equivalent to olanzapine', 'panss_t'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件\n",
    "patients_df = pd.read_excel('预处理后的数据集B前测.xlsx')  # SCZ 组\n",
    "df = pd.read_excel('预处理后的数据集A.xlsx')  # 原始数据集\n",
    "\n",
    "# 统一列名格式（小写，去空格，替换符号）\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace('-', '_').str.replace(',', '')\n",
    "    return df\n",
    "\n",
    "patients_df = clean_columns(patients_df)\n",
    "df = clean_columns(df)\n",
    "\n",
    "# 筛选健康对照组（Group = 2）\n",
    "control_df = df[df['group'] == 2].copy()\n",
    "\n",
    "# 打印实际的列名，确保匹配\n",
    "print(\"SCZ 数据集的列名:\", patients_df.columns.tolist())\n",
    "print(\"HC 数据集的列名:\", control_df.columns.tolist())\n",
    "\n",
    "# 重新定义 behavior_variables，确保与实际列名匹配\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc',\n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "# 确保 behavior_variables 在数据集中存在\n",
    "def check_columns(df, dataset_name):\n",
    "    missing_columns = [col for col in behavior_variables if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"{dataset_name} 数据集中缺少以下列，请检查拼写或格式: {missing_columns}\")\n",
    "\n",
    "check_columns(patients_df, \"SCZ\")\n",
    "check_columns(control_df, \"HC\")\n",
    "\n",
    "# 统一 Group 字段大小写\n",
    "for df in [patients_df, control_df]:\n",
    "    df['group'] = pd.to_numeric(df['group'], errors='coerce')\n",
    "    df.dropna(subset=['group'], inplace=True)\n",
    "\n",
    "# 确保数据集不为空\n",
    "if patients_df.empty or control_df.empty:\n",
    "    raise ValueError(\"筛选出的患者组或对照组为空，请检查 Group 字段的值是否正确！\")\n",
    "\n",
    "# 定义其他变量\n",
    "continuous_variables = ['age', 'education_years']\n",
    "categorical_variables = ['gender']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "def one_hot_encode(df, categorical_vars):\n",
    "    for var in categorical_vars:\n",
    "        if var in df.columns:\n",
    "            dummies = pd.get_dummies(df[var], prefix=var, drop_first=True)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "patients_df = one_hot_encode(patients_df, categorical_variables)\n",
    "control_df = one_hot_encode(control_df, categorical_variables)\n",
    "\n",
    "# 标准化连续变量\n",
    "scaler = StandardScaler()\n",
    "control_df[continuous_variables] = scaler.fit_transform(control_df[continuous_variables])\n",
    "patients_df[continuous_variables] = scaler.transform(patients_df[continuous_variables])\n",
    "\n",
    "# 从对照组DataFrame中提取行为变量数据\n",
    "control_data = control_df[behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(control_data)\n",
    "\n",
    "# 使用对照组的标准化参数标准化患者组数据\n",
    "standardized_patient_data = scaler.transform(patients_df[behavior_variables])\n",
    "standardized_patient_df = pd.DataFrame(standardized_patient_data, columns=behavior_variables)\n",
    "\n",
    "# 处理 Healthy Controls 组\n",
    "standardized_control_data = scaler.transform(control_df[behavior_variables])\n",
    "standardized_control_df = pd.DataFrame(standardized_control_data, columns=behavior_variables)\n",
    "\n",
    "# 从数据框中获取所有人口学变量（已独热编码和标准化）\n",
    "demographic_variables = [col for col in control_df.columns if col not in behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合回归模型校正人口学效应\n",
    "corrected_patient_data = pd.DataFrame()\n",
    "corrected_control_data = pd.DataFrame()\n",
    "\n",
    "for variable in behavior_variables:\n",
    "    model = LinearRegression()\n",
    "    model.fit(control_df[demographic_variables], control_df[variable])\n",
    "    correction_patients = model.predict(patients_df[demographic_variables])\n",
    "    correction_controls = model.predict(control_df[demographic_variables])\n",
    "    corrected_patient_data[variable] = standardized_patient_df[variable] - correction_patients\n",
    "    corrected_control_data[variable] = standardized_control_df[variable] - correction_controls\n",
    "\n",
    "# 保存患者组和健康对照组的校正并标准化后的数据\n",
    "corrected_patient_df = pd.DataFrame(corrected_patient_data)\n",
    "corrected_control_df = pd.DataFrame(corrected_control_data)\n",
    "\n",
    "corrected_patient_df.to_excel('./table/校正并标准化后的患者行为变量数据-数据集B前测.xlsx', index=False)\n",
    "corrected_control_df.to_excel('./table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx', index=False)\n",
    "\n",
    "# 打印校正并标准化后的DataFrame\n",
    "print(corrected_patient_df.head())\n",
    "print(corrected_control_df.head())\n",
    "\n",
    "print(\"校正并标准化完成，数据已保存到 './table/校正并标准化后的患者行为变量数据-数据集B前测.xlsx' 和 './table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx'.\")\n",
    "\n",
    "# 计算校正并标准化后的均值和标准差\n",
    "corrected_patient_means = corrected_patient_df.mean().round(2)\n",
    "corrected_patient_stds = corrected_patient_df.std().round(2)\n",
    "corrected_control_means = corrected_control_df.mean().round(2)\n",
    "corrected_control_stds = corrected_control_df.std().round(2)\n",
    "\n",
    "# 创建一个DataFrame来存储结果，以“均值±标准差”格式显示\n",
    "summary_df = pd.DataFrame({\n",
    "    'Corrected and Standardized Patient': corrected_patient_means.astype(str) + ' ± ' + corrected_patient_stds.astype(str),\n",
    "    'Corrected and Standardized Control': corrected_control_means.astype(str) + ' ± ' + corrected_control_stds.astype(str)\n",
    "}, index=behavior_variables)\n",
    "\n",
    "# 打印结果\n",
    "print(summary_df)\n",
    "\n",
    "# 保存结果为Excel文件\n",
    "summary_df.to_excel('./table/校正并标准化后的行为变量均值和标准差-数据集B前测.xlsx')\n",
    "\n",
    "print(\"校正并标准化后的均值和标准差已保存到 './table/校正并标准化后的行为变量均值和标准差-数据集B前测.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集B后测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCZ 数据集的列名: ['id', 'group', 'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', 'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span', 'age', 'education_years', 'gender']\n",
      "HC 数据集的列名: ['id', 'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc', 'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span', 'group', 'age', 'gender', 'education_years']\n",
      "   stroop_incongruent_rt  stroop_interference_effect_rt  nogo_acc  \\\n",
      "0            -752.351951                     740.531060 -1.028934   \n",
      "1            -766.634835                     747.550381 -0.385461   \n",
      "2            -754.255204                     734.327982 -0.751407   \n",
      "3            -750.947657                     731.416278 -1.400554   \n",
      "4            -766.432796                     734.028803 -0.570903   \n",
      "\n",
      "   switch_cost  rm_1750_acc  rm_750_acc  dsbt_span  \n",
      "0  -315.714885    -0.409673   -2.009067  -3.814494  \n",
      "1  -265.925093     0.129953    0.264539  -6.602839  \n",
      "2  -292.207685     0.153232    0.076111  -5.993983  \n",
      "3  -314.170530    -0.606298    0.090937  -4.300204  \n",
      "4  -257.684005    -0.263520    0.649739  -6.337077  \n",
      "   stroop_incongruent_rt  stroop_interference_effect_rt  nogo_acc  \\\n",
      "0            -668.468770                     472.737383 -0.341290   \n",
      "1            -658.860649                     462.189560 -1.831999   \n",
      "2            -690.228184                     492.043867 -1.054630   \n",
      "3            -687.131249                     488.666539 -0.065394   \n",
      "4            -682.397528                     483.146635 -0.713083   \n",
      "\n",
      "   switch_cost  rm_1750_acc  rm_750_acc  dsbt_span  \n",
      "0  -185.483299     0.072327   -0.084050  -5.424842  \n",
      "1  -172.597758     0.257514   -0.105744  -5.891134  \n",
      "2  -239.178533     0.531875    0.323126  -5.517346  \n",
      "3  -198.719864     0.274264    0.912996  -4.823242  \n",
      "4  -227.702450    -0.480533    0.545471  -6.762047  \n",
      "校正并标准化完成，数据已保存到 './table/校正并标准化后的患者行为变量数据-数据集B后测.xlsx' 和 './table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx'.\n",
      "                              Corrected and Standardized Patient  \\\n",
      "stroop_incongruent_rt                            -685.88 ± 46.15   \n",
      "stroop_interference_effect_rt                    485.31 ± 190.29   \n",
      "nogo_acc                                            -1.43 ± 1.17   \n",
      "switch_cost                                      -227.41 ± 63.29   \n",
      "rm_1750_acc                                         -1.53 ± 1.48   \n",
      "rm_750_acc                                           -1.4 ± 1.55   \n",
      "dsbt_span                                           -6.34 ± 1.07   \n",
      "\n",
      "                              Corrected and Standardized Control  \n",
      "stroop_incongruent_rt                            -663.61 ± 32.74  \n",
      "stroop_interference_effect_rt                     384.97 ± 74.52  \n",
      "nogo_acc                                             -0.88 ± 1.0  \n",
      "switch_cost                                      -198.95 ± 39.48  \n",
      "rm_1750_acc                                          -0.74 ± 1.0  \n",
      "rm_750_acc                                          -0.66 ± 0.99  \n",
      "dsbt_span                                           -6.06 ± 1.03  \n",
      "校正并标准化后的均值和标准差已保存到 './table/校正并标准化后的行为变量均值和标准差-数据集B后测.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件\n",
    "patients_df = pd.read_excel('预处理后的数据集B后测.xlsx')  # SCZ 组\n",
    "df = pd.read_excel('预处理后的数据集A.xlsx')  # 原始数据集\n",
    "\n",
    "# 统一列名格式（小写，去空格，替换符号）\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace('-', '_').str.replace(',', '')\n",
    "    return df\n",
    "\n",
    "patients_df = clean_columns(patients_df)\n",
    "df = clean_columns(df)\n",
    "\n",
    "# 筛选健康对照组（Group = 2）\n",
    "control_df = df[df['group'] == 2].copy()\n",
    "\n",
    "# 打印实际的列名，确保匹配\n",
    "print(\"SCZ 数据集的列名:\", patients_df.columns.tolist())\n",
    "print(\"HC 数据集的列名:\", control_df.columns.tolist())\n",
    "\n",
    "# 重新定义 behavior_variables，确保与实际列名匹配\n",
    "behavior_variables = [\n",
    "    'stroop_incongruent_rt', 'stroop_interference_effect_rt', 'nogo_acc',\n",
    "    'switch_cost', 'rm_1750_acc', 'rm_750_acc', 'dsbt_span'\n",
    "]\n",
    "\n",
    "# 确保 behavior_variables 在数据集中存在\n",
    "def check_columns(df, dataset_name):\n",
    "    missing_columns = [col for col in behavior_variables if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"{dataset_name} 数据集中缺少以下列，请检查拼写或格式: {missing_columns}\")\n",
    "\n",
    "check_columns(patients_df, \"SCZ\")\n",
    "check_columns(control_df, \"HC\")\n",
    "\n",
    "# 统一 Group 字段大小写\n",
    "for df in [patients_df, control_df]:\n",
    "    df['group'] = pd.to_numeric(df['group'], errors='coerce')\n",
    "    df.dropna(subset=['group'], inplace=True)\n",
    "\n",
    "# 确保数据集不为空\n",
    "if patients_df.empty or control_df.empty:\n",
    "    raise ValueError(\"筛选出的患者组或对照组为空，请检查 Group 字段的值是否正确！\")\n",
    "\n",
    "# 定义其他变量\n",
    "continuous_variables = ['age', 'education_years']\n",
    "categorical_variables = ['gender']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "def one_hot_encode(df, categorical_vars):\n",
    "    for var in categorical_vars:\n",
    "        if var in df.columns:\n",
    "            dummies = pd.get_dummies(df[var], prefix=var, drop_first=True)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "patients_df = one_hot_encode(patients_df, categorical_variables)\n",
    "control_df = one_hot_encode(control_df, categorical_variables)\n",
    "\n",
    "# 标准化连续变量\n",
    "scaler = StandardScaler()\n",
    "control_df[continuous_variables] = scaler.fit_transform(control_df[continuous_variables])\n",
    "patients_df[continuous_variables] = scaler.transform(patients_df[continuous_variables])\n",
    "\n",
    "# 从对照组DataFrame中提取行为变量数据\n",
    "control_data = control_df[behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(control_data)\n",
    "\n",
    "# 使用对照组的标准化参数标准化患者组数据\n",
    "standardized_patient_data = scaler.transform(patients_df[behavior_variables])\n",
    "standardized_patient_df = pd.DataFrame(standardized_patient_data, columns=behavior_variables)\n",
    "\n",
    "# 处理 Healthy Controls 组\n",
    "standardized_control_data = scaler.transform(control_df[behavior_variables])\n",
    "standardized_control_df = pd.DataFrame(standardized_control_data, columns=behavior_variables)\n",
    "\n",
    "# 从数据框中获取所有人口学变量（已独热编码和标准化）\n",
    "demographic_variables = [col for col in control_df.columns if col not in behavior_variables]\n",
    "\n",
    "# 使用对照组数据拟合回归模型校正人口学效应\n",
    "corrected_patient_data = pd.DataFrame()\n",
    "corrected_control_data = pd.DataFrame()\n",
    "\n",
    "for variable in behavior_variables:\n",
    "    model = LinearRegression()\n",
    "    model.fit(control_df[demographic_variables], control_df[variable])\n",
    "    correction_patients = model.predict(patients_df[demographic_variables])\n",
    "    correction_controls = model.predict(control_df[demographic_variables])\n",
    "    corrected_patient_data[variable] = standardized_patient_df[variable] - correction_patients\n",
    "    corrected_control_data[variable] = standardized_control_df[variable] - correction_controls\n",
    "\n",
    "# 保存患者组和健康对照组的校正并标准化后的数据\n",
    "corrected_patient_df = pd.DataFrame(corrected_patient_data)\n",
    "corrected_control_df = pd.DataFrame(corrected_control_data)\n",
    "\n",
    "corrected_patient_df.to_excel('./table/校正并标准化后的患者行为变量数据-数据集B后测.xlsx', index=False)\n",
    "corrected_control_df.to_excel('./table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx', index=False)\n",
    "\n",
    "# 打印校正并标准化后的DataFrame\n",
    "print(corrected_patient_df.head())\n",
    "print(corrected_control_df.head())\n",
    "\n",
    "print(\"校正并标准化完成，数据已保存到 './table/校正并标准化后的患者行为变量数据-数据集B后测.xlsx' 和 './table/校正并标准化后的健康对照行为变量数据-数据集A.xlsx'.\")\n",
    "\n",
    "# 计算校正并标准化后的均值和标准差\n",
    "corrected_patient_means = corrected_patient_df.mean().round(2)\n",
    "corrected_patient_stds = corrected_patient_df.std().round(2)\n",
    "corrected_control_means = corrected_control_df.mean().round(2)\n",
    "corrected_control_stds = corrected_control_df.std().round(2)\n",
    "\n",
    "# 创建一个DataFrame来存储结果，以“均值±标准差”格式显示\n",
    "summary_df = pd.DataFrame({\n",
    "    'Corrected and Standardized Patient': corrected_patient_means.astype(str) + ' ± ' + corrected_patient_stds.astype(str),\n",
    "    'Corrected and Standardized Control': corrected_control_means.astype(str) + ' ± ' + corrected_control_stds.astype(str)\n",
    "}, index=behavior_variables)\n",
    "\n",
    "# 打印结果\n",
    "print(summary_df)\n",
    "\n",
    "# 保存结果为Excel文件\n",
    "summary_df.to_excel('./table/校正并标准化后的行为变量均值和标准差-数据集B后测.xlsx')\n",
    "\n",
    "print(\"校正并标准化后的均值和标准差已保存到 './table/校正并标准化后的行为变量均值和标准差-数据集B后测.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
